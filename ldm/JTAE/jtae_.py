# -*- coding: utf-8 -*-
"""jtae_.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I5GbEmbZ5UBc_JrJE-ZcNvUubgv36RoJ
"""

import torch
from torch import nn
import argparse
import numpy as np
import sys
sys.path.append("C:/Users/USER/Documents/model")
from JTAE.bneck import BaseBottleneck
from JTAE.convolution import Block
from JTAE.positionalencoding import PositionalEncoding
from ConDiff.ConditionalDiffusion.conditionaldenoisingmodel import UNet
from ConDiff.ConditionalDiffusion.gaussiandiffusion import GaussianDiffusionTrainer
from performer_pytorch import Performer

class jtae(nn.Module):
    def __init__(self, hparams):
        super(jtae, self).__init__()

        if isinstance(hparams, dict):
            hparams = argparse.Namespace(**hparams)

        self.hparams = hparams
        self.input_dim = hparams.input_dim
        self.latent_dim = hparams.latent_dim
        self.hidden_dim = hparams.hidden_dim
        self.seq_len = hparams.seq_len
        self.device = hparams.device
        self.num_classes = hparams.num_labels
        self.kernel_size = hparams.kernel_size
        self.embedding_dim = hparams.embedding_dim
        self.z_rep = None
        self.layers = hparams.layers
        self.probs = hparams.probs
        self.nhead = 4
        self.gamma = hparams.gamma_val

        self.sigma = hparams.sigma_val
        self.diff_loss = 0
        self.device = hparams.device
        try:
            self.eta = hparams.eta_val
        except:
            self.eta = 1.0

        # Embedding
        self.embed = nn.Embedding(self.input_dim, self.embedding_dim)

        # Positional Encoding
        self.pos_encoder = PositionalEncoding(
            d_model=self.embedding_dim, max_len=self.seq_len
        )

        # Global Attention
        self.glob_attn_module = nn.Sequential(
            nn.Linear(self.embedding_dim, 1), nn.Softmax(dim=1)
        )

        # Performer Encoder
        self.performer_encoder = Performer(
            dim=self.embedding_dim,
            depth=self.layers,
            heads=self.nhead,
            dim_head=self.embedding_dim // self.nhead,
            causal=True,
            ff_dropout=self.probs,
            attn_dropout=self.probs,
            )


        # Bottleneck Module
        self.bottleneck_module = BaseBottleneck(self.embedding_dim, self.latent_dim)

        # Decoder
        self._build_decoder(hparams)

        # Diffusion model
        self.diff_model = UNet(
            T=hparams.dif_T,
            num_classes=hparams.num_labels,
            ch=hparams.dif_channel,
            ch_mult=hparams.dif_channel_mult,
            num_res_blocks=hparams.dif_res_blocks,
            dropout=hparams.dif_dropout
        )

        self.Gaussian_Diffusion_Trainer = GaussianDiffusionTrainer(
            model=self.diff_model,
            beta_1=hparams.dif_beta_1,
            beta_T=hparams.dif_beta_T,
            T=hparams.dif_T
        )

    def _build_decoder(self, hparams):
        self.dec_conv_module = nn.ModuleList([
            nn.Linear(self.latent_dim, self.seq_len * (self.hidden_dim // 2)),
            Block(self.hidden_dim // 2, self.hidden_dim),
            nn.Conv1d(self.hidden_dim, self.input_dim, kernel_size=3, padding=1),
        ])

    def transformer_encoding(self, embedded_batch):
        """
        Uses Performer to encode input sequence.
        Input: B x S x E
        Output: B x S x E
        """
        pos_encoded_batch = self.pos_encoder(embedded_batch)
        output_embed = self.performer_encoder(pos_encoded_batch)
        return output_embed

    def encode(self, batch):
        embedded_batch = self.embed(batch)                    # (B, S, E)
        output_embed = self.transformer_encoding(embedded_batch)
        glob_attn = self.glob_attn_module(output_embed)       # (B, S, 1)
        z_rep = torch.bmm(glob_attn.transpose(-1, 1), output_embed).squeeze()

        if len(embedded_batch) == 1:
            z_rep = z_rep.unsqueeze(0)

        z_rep = self.bottleneck_module(z_rep)                 # (B, latent_dim)
        return z_rep

    def decode(self, z_rep):
        h_rep = z_rep
        for idx, layer in enumerate(self.dec_conv_module):
            if idx == 1:
                h_rep = h_rep.reshape(-1, self.hidden_dim // 2, self.seq_len)
            h_rep = layer(h_rep)
        return h_rep  # (B, input_dim, seq_len)

    def diff_train(self, z_rep, y, c):
        b = z_rep.shape[0]
        if np.random.rand() < 0.1:
            y = torch.zeros_like(y)
        loss = self.Gaussian_Diffusion_Trainer(z_rep, c, y)
        loss = loss.sum() / (b ** 2)
        return loss

    def forward(self, x, y, c):
        z_rep = self.encode(x)               # (B, latent_dim)
        z_rep = z_rep.unsqueeze(1)           # (B, 1, latent_dim)
        diff_loss = self.diff_train(z_rep, y, c)
        z_rep = z_rep.squeeze(1)             # (B, latent_dim)
        x_hat = self.decode(z_rep)           # (B, input_dim, seq_len)
        return x_hat, z_rep, diff_loss